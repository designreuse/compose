version: "3.7"
services:
  # The environment variable "ELASTIC_VERSION" is used throughout this file to
  # specify the version of the images to run. The default is set in the
  # '.env' file in this folder. It can be overridden with any normal
  # technique for setting environment variables, for example:
  #
  #   ELASTIC_VERSION=5.5.1 docker-compose up
  #
  # Additionally, the user can control:
  #   * the total memory assigned to the ES container through the variable ES_MEM_LIMIT e.g. ES_MEM_LIMIT=2g
  #   * the memory assigned to the ES JVM through the variable ES_JVM_HEAP e.g. ES_JVM_SIZE=1024m
  #   * the password used for the elastic, logstash_system and kibana accounts through the variable ES_PASSWORD
  #   * the mysql root password through the var MYSQL_ROOT_PASSWORD
  #   * the default index pattern used in kibana via the var DEFAULT_INDEX_PATTERN
  #   * the ES heap size through tt
  # REF: https://docs.docker.com/compose/compose-file/#variable-substitution
  #

  #Elasticsearch container
  elasticsearch:
#    container_name: elasticsearch
    hostname: elasticsearch
    image: "docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION:-5.5.1}"
    environment:
      - http.host=0.0.0.0
      - transport.host=127.0.0.1
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms${ES_JVM_HEAP:-1024m} -Xmx${ES_JVM_HEAP:-1024m}"
#    mem_limit: ${ES_MEM_LIMIT:-2g}
#    ulimits:
#      memlock:
#        soft: -1
#        hard: -1
    configs:
    - source: elastic_config
      target: /usr/share/elasticsearch/elasticsearch.yml
    volumes:
    - elasticsearch:/usr/share/elasticsearch/data
    #Port 9200 is available on the host. Need to for user to access as well as Packetbeat
    ports: ['9200:9200']
    #Healthcheck to confirm availability of ES. Other containers wait on this.
    healthcheck:
      test: ["CMD", "curl","-s" ,"-f", "-u", "elastic:${ES_PASSWORD:-changeme}", "http://localhost:9200/_cat/health"]
    #Internal network for the containers
    networks:
    - logging
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s
      resources:
        reservations:
          memory: ${ES_MEM_LIMIT:-2g}
        limits:
          memory: ${ES_MEM_LIMIT:-2g}

  #Kibana container
  kibana:
#    container_name: kibana
    hostname: kibana
    image: "docker.elastic.co/kibana/kibana:${ELASTIC_VERSION:-5.5.1}"
    configs:
    - source: kibana_config
      target: /usr/share/kibana/kibana.yml
    #Port 5601 accessible on the host
    ports: ['5601:5601']
    networks:
    - logging
    #We don't start Kibana until the ES instance is ready
    depends_on:
    - elasticsearch
    environment:
      - "ELASTICSEARCH_PASSWORD=${ES_PASSWORD:-changeme}"
    healthcheck:
      test: ["CMD", "curl", "-s", "-f", "http://localhost:5601/login"]
      retries: 6
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s
      resources:
        reservations:
          memory: 256m
        limits:
          memory: 512m

  #Heartbeat container
  heartbeat:
#    container_name: heartbeat
    hostname: heartbeat
    image: "docker.elastic.co/beats/heartbeat:${ELASTIC_VERSION:-5.5.1}"
#    volumes:
      #Mount the heartbeat configuration so users can make edits
    configs:
    - source: heartbeat_config
      target: /usr/share/heartbeat/heartbeat.yml
    depends_on:
      - elasticsearch
#      :  { condition: service_healthy }
    environment:
      - "ES_PASSWORD=${ES_PASSWORD:-changeme}"
    command: heartbeat -e -E output.elasticsearch.username=elastic -E output.elasticsearch.password=${ES_PASSWORD:-changeme} -strict.perms=false
    networks:
    - logging
#    restart: on-failure
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Filebeat container
  filebeat:
#    container_name: filebeat
    hostname: filebeat
    user: root
    image: "docker.elastic.co/beats/filebeat:${ELASTIC_VERSION:-5.5.1}"
    configs:
    #Mount the filebeat configuration so users can make edit
    - source: filebeat_config
      target: /usr/share/filebeat/filebeat.yml
    #Mount the prospectors directory. Users can in turn add propspectors to this directory and they will be dynamically loaded
    - source: prospectors_config
      target: /usr/share/filebeat/prospectors.d/docker.yml
    volumes:
      #Mount the nginx logs into the filebeat container so we can access and index them using the filebeat nginx module
      - logs-nginx:/var/log/nginx/
      #Mount the apache2 logs into the filebeat container so we can access and index them using the filebeat apache2 module
      - logs-apache2:/var/log/apache2/
      #Mount the mysql logs into the filebeat container so we can access and and index them using the filebeat mysql module
      - logs-mysql:/var/log/mysql/
      #Mount the hosts system log directory. This represents the logs of the VM hosting docker. Consumed by the filebeat system module.
      - /var/log/:/var/log/host/
      #:ro
      #Mount the docker logs for indexing by the custom prospector ./config/filebeat/prospectors.d
      - /var/lib/docker/containers:/hostfs/var/lib/docker/containers
      #Named volume fsdata. This is used to persist the registry file between restarts, so to avoid data duplication
      - fbdata:/usr/share/filebeat/data/
    networks:
    - logging
    command: filebeat -e -E output.elasticsearch.username=elastic -E output.elasticsearch.password=${ES_PASSWORD:-changeme} -strict.perms=false
#    restart: on-failure
    depends_on:
      #wait for the these services to come up. This ensures the logs are available and ES exists for indexing
      - elasticsearch
#      :  { condition: service_healthy }
      - nginx
#      : { condition: service_started }
      - apache2
#      : { condition: service_started }
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
      labels:
      - com.df.notify=true
      - com.df.distribute=true
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Metricbeat container
  metricbeat:
#    container_name: metricbeat
    hostname: metricbeat
    user: root
    image: docker.elastic.co/beats/metricbeat:${ELASTIC_VERSION:-5.5.1}
    configs:
    #Mount the metricbeat configuration so users can make edit
    - source: metricbeat_config
      target: /usr/share/metricbeat/metricbeat.yml
      #Mount the modules.d directory into the container. This allows user to potentially make changes to the modules and they will be dynamically loaded.
    - source: metricbeat_apache_config
      target: /usr/share/metricbeat/modules.d/apache.yml
    - source: metricbeat_docker_config
      target: /usr/share/metricbeat/modules.d/docker.yml
    - source: metricbeat_mysql_config
      target: /usr/share/metricbeat/modules.d/mysql.yml
    - source: metricbeat_nginx_config
      target: /usr/share/metricbeat/modules.d/nginx.yml
    - source: metricbeat_system_config
      target: /usr/share/metricbeat/modules.d/system.yml
    volumes:
      # The commented sections below enable Metricbeat to monitor the Docker host rather than the Metricbeat container. These are used by the system module.
      - /proc:/hostfs/proc
      #:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup
      #:ro
      #Allows us to report on docker from the hosts information
      - /var/run/docker.sock:/var/run/docker.sock
      #We mount the host filesystem so we can report on disk usage with the system module
      - /:/hostfs
      #:ro
    command: metricbeat -e -system.hostfs=/hostfs -E output.elasticsearch.username=elastic -E output.elasticsearch.password=${ES_PASSWORD:-changeme} -strict.perms=false
    networks:
    - logging
#    restart: on-failure
    environment:
      - "MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD:-changeme}"
    depends_on:
      #wait for the these services to come up. This ensures the logs are available and ES exists for indexing
      - elasticsearch
#        :  { condition: service_healthy }
      - nginx
#        : { condition: service_started }
      - apache2
#        : { condition: service_started }
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
      labels:
      - com.df.notify=true
      - com.df.distribute=true
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Packetbeat container
  packetbeat:
#    container_name: packetbeat
    hostname: packetbeat
    image: "docker.elastic.co/beats/packetbeat:${ELASTIC_VERSION:-5.5.1}"
    configs:
    #Mount the filebeat configuration so users can make edit
    - source: packetbeat_config
      target: /usr/share/packetbeat/packetbeat.yml
    # Packetbeat needs some elevated privileges to capture network traffic.
    # We'll grant them with POSIX capabilities.
#    cap_add: ['NET_RAW', 'NET_ADMIN']
    # Use "host mode" networking to allow Packetbeat to capture traffic from
    # the real network interface on the host, rather than being isolated to the
    # container's virtual interface.
#    network_mode: host
    command: packetbeat -e -E output.elasticsearch.hosts='["localhost:9200"]' -E output.elasticsearch.username=elastic -E output.elasticsearch.password=${ES_PASSWORD:-changeme} -strict.perms=false
    depends_on:
      #Wait for ES to be up before we start collecting
      - elasticsearch
#        :  { condition: service_healthy }
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Nginx container
  nginx:
#    container_name: nginx
    hostname: nginx
#    build: ${PWD}/config/nginx
    image: uscdev/nginx
    networks:
    - logging
    #Expose port 80 to allow users to hit content and generate data for filebeat and packetbeat
    ports: ['80:80']
    command: nginx -g 'daemon off;'
    volumes:
      #Logs are mounted to a relative path. These are also accessed by Filebeat and consumed by the Nginx module
      - logs-nginx:/var/log/nginx/
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Apache2 container
  apache2:
#    container_name: apache2
    hostname: apache2
#    build: ${PWD}/config/apache2
    image: uscdev/apache2
    networks:
    - logging
    #Expose port 80 as port 800 to allow users to hit content and generate data for filebeat and packetbeat
    ports: ['8000:80']
    volumes:
      #Logs are mounted to a relative path. These are also accessed by Filebeat and consumed by the Apache module
      - logs-apache2:/var/log/apache2/
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Mysql container
  mysql:
#    container_name: mqsql
    hostname: mysql
#    build: ${PWD}/config/mysql
    image: uscdev/mysql
    environment:
      - "MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD:-changeme}"
    networks:
    - logging
    #Expose port 3306 to allow users to connect and perform operations. These will be picked up by Packetbeat, Filebeat and Metricbeat
    ports: ['3306:3306']
    command: bash -c "chown -R mysql:mysql /var/log/mysql && exec /entrypoint.sh mysqld"
    volumes:
      #Use named volume so mysql data is persisted across restart
      - mysqldata:/var/lib/mysql/
      #Logs are mounted to a relative path. These are also accessed by Filebeat and consumed by the Mysql module
      - logs-mysql:/var/log/mysql/
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      labels:
      - com.df.distribute=true
      - com.df.notify=true
      - com.df.port=80
      - com.df.alertName=memlimit
      - com.df.alertIf=@service_mem_limit:0.8
      - com.df.alertFor=30s

  #Configure Stack container. This short lived container configures the stack once Kibana and Elasticsearch are available. More specifically, using a script it sets passwords, import dashboards, sets a default index pattern, loads templates and pipelines
  configure_stack:
#    container_name: configure_stack
    image: docker.elastic.co/beats/metricbeat:${ELASTIC_VERSION:-5.5.1}
    configs:
    - source: configure-stack
      target: /usr/local/bin/configure-stack.sh
#      read-only
    - source: pipelines
      target: /usr/local/bin/pipelines/docker-logs.json
    - source: templates
      target: /usr/local/bin/templates/docker-logs.json
#    volumes: ['./init/configure-stack.sh:/usr/local/bin/configure-stack.sh:ro','./init/pipelines/:/usr/local/bin/pipelines/','./init/templates/:/usr/local/bin/templates/']
    command: ['/bin/bash', '-c', 'cat /usr/local/bin/configure-stack.sh | tr -d "\r" | bash']
    networks:
    - logging
    environment: ['ELASTIC_VERSION=${ELASTIC_VERSION:-5.5.1}','ES_PASSWORD=${ES_PASSWORD:-changeme}','DEFAULT_INDEX_PATTERN=${DEFAULT_INDEX_PATTERN:-metricbeat-*}']
    depends_on:
    - elasticsearch
    - kibana
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: none

volumes:
  elasticsearch:
    external: true
  mysqldata:
    external: true
  logs-mysql:
    driver: local
  logs-nginx:
    driver: local
  logs-apache2:
    driver: local
  fbdata:
    driver: local

configs:
  configure-stack:
    file: ./init/configure-stack.sh
  pipelines:
    file: ./init/pipelines/docker-logs.json
  templates:
    file: ./init/templates/docker-logs.json
  elastic_config:
    file: ./config/elasticsearch/elasticsearch.yml
  kibana_config:
    file: ./config/kibana/kibana.yml
  heartbeat_config:
    file: ./config/beats/heartbeat/heartbeat.yml
  filebeat_config:
    file: ./config/beats/filebeat/filebeat.yml
  prospectors_config:
    file: ./config/beats/filebeat/prospectors.d/docker.yml
  packetbeat_config:
    file: ./config/beats/packetbeat/packetbeat.yml
  metricbeat_config:
    file: ./config/beats/metricbeat/metricbeat.yml
  metricbeat_apache_config:
    file: ./config/beats/metricbeat/modules.d/apache.yml
  metricbeat_docker_config:
    file: ./config/beats/metricbeat/modules.d/docker.yml
  metricbeat_mysql_config:
    file: ./config/beats/metricbeat/modules.d/mysql.yml
  metricbeat_nginx_config:
    file: ./config/beats/metricbeat/modules.d/nginx.yml
  metricbeat_system_config:
    file: ./config/beats/metricbeat/modules.d/system.yml

networks:
  default:
    driver: overlay
  logging:
    external: true

#volumes:
#  #Es data
#  esdata:
#    driver: local
#  #Filebeat data i.e. registry file
#  fbdata:
#    driver: local
#networks: {stack: {}}
#
#
#
#configs:
#  logstash_config:
#    file: ./logstash/config/logstash.yml
#  logstash_pipeline:
#    file: ./logstash/pipeline/logstash.conf
#
#networks:
#  default:
#    driver: overlay
#  proxy:
#    external: true
